{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5262879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BIC, BDeu, BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import entropy\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56006570-18af-48ad-889d-58442d23089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  price_mentioned food_mentioned service_mentioned cleanliness_mentioned  \\\n",
      "0              no             no                no                    no   \n",
      "1              no             no                no                    no   \n",
      "2              no            yes                no                    no   \n",
      "3              no             no               yes                   yes   \n",
      "4              no             no                no                    no   \n",
      "\n",
      "   star_rating  \n",
      "0          5.0  \n",
      "1          5.0  \n",
      "2          5.0  \n",
      "3          5.0  \n",
      "4          4.0  \n",
      "Parsed 230 reviews for this business.\n",
      "(230, 5)\n"
     ]
    }
   ],
   "source": [
    "# Use keyword heuristics to define latent variables (instead of LDA)\n",
    "\n",
    "PRICE_KEYWORDS = {\"expensive\", \"pricey\", \"affordable\", \"overpriced\", \"prices\"}\n",
    "FOOD_KEYWORDS = {\"food\", \"dish\", \"meal\", \"taste\", \"flavor\", \"portion\", \"menu\", \"delicious\"}\n",
    "SERVICE_KEYWORDS = {\"waiter\", \"waitress\", \"staff\", \"rude\", \"slow\", \"friendly\", \"host\", \"service\"}\n",
    "CLEANLINESS_KEYWORDS = {\"clean\", \"dirty\", \"bathroom\", \"restroom\", \"table\", \"floor\", \"smell\"}\n",
    "\n",
    "def contains_keywords(text, keyword_set, min_hits=2):\n",
    "    # returns True if text contains enough words within keyword_set\n",
    "    text_lower = text.lower()\n",
    "    return sum(1 for kw in keyword_set if kw in text_lower) >= min_hits\n",
    "\n",
    "def extract_features(review_json):\n",
    "    # preps review for panda dataframe\n",
    "    text = review_json[\"text\"]\n",
    "    return {\n",
    "        \"price_mentioned\": \"yes\" if contains_keywords(text, PRICE_KEYWORDS) else \"no\",\n",
    "        \"food_mentioned\": \"yes\" if contains_keywords(text, FOOD_KEYWORDS) else \"no\",\n",
    "        \"service_mentioned\": \"yes\" if contains_keywords(text, SERVICE_KEYWORDS) else \"no\",\n",
    "        \"cleanliness_mentioned\": \"yes\" if contains_keywords(text, CLEANLINESS_KEYWORDS) else \"no\",\n",
    "        \"star_rating\": float(review_json[\"stars\"])\n",
    "    }\n",
    "\n",
    "def get_business_id(business_name, business_json_path=\"data/yelp_academic_dataset_business.json\"):\n",
    "    # Retrieves serial business ID and returns it\n",
    "    with open(business_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            biz = json.loads(line)\n",
    "            if biz[\"name\"].lower() == business_name.lower():\n",
    "                return biz[\"business_id\"]\n",
    "    raise ValueError(f\"Business '{business_name}' not found in dataset.\")\n",
    "\n",
    "def load_reviews_df(business_name, reviews_path=\"sample_reviews.json\", business_path=\"data/yelp_academic_dataset_business.json\"):\n",
    "    # Extracts all relevant reviews from business name parameter and consolidates it all into a panda dataframe\n",
    "    business_id = get_business_id(business_name, business_path)\n",
    "\n",
    "    reviews = []\n",
    "    with open(reviews_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            review = json.loads(line)\n",
    "            if review[\"business_id\"] == business_id:\n",
    "                reviews.append(extract_features(review))\n",
    "\n",
    "    return pd.DataFrame(reviews)\n",
    "\n",
    "def display_sample():\n",
    "    with open(\"sample_reviews.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        reviews = [json.loads(line) for line in f]  # fallback for line-delimited\n",
    "\n",
    "    sample_biz_ids = {r[\"business_id\"] for r in reviews}\n",
    "    found_names = []\n",
    "\n",
    "    with open(\"data/yelp_academic_dataset_business.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            biz = json.loads(line)\n",
    "            if biz[\"business_id\"] in sample_biz_ids:\n",
    "                found_names.append((biz[\"name\"], biz[\"city\"], biz[\"state\"]))\n",
    "\n",
    "    for name, city, state in sorted(found_names):\n",
    "        print(f\"- {name} â€” {city}, {state}\")\n",
    "\n",
    "\n",
    "#display_sample()   \n",
    "# Use load_reviews to create pandas dataframe for model training.\n",
    "df = load_reviews_df(\"In-N-Out Burger\", \"data/yelp_academic_dataset_review.json\")\n",
    "print(df.head())\n",
    "print(f\"Parsed {len(df)} reviews for this business.\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0028b",
   "metadata": {},
   "source": [
    "Lets create a structure for our model and fit the data. From here we can create an inference from pgmpy to create queries to find out which aspects have the most impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93b58fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'price_mentioned': 'C', 'food_mentioned': 'C', 'service_mentioned': 'C', 'cleanliness_mentioned': 'C', 'star_rating': 'N'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_mentioned: delta = 0.008\n",
      "service_mentioned: delta = -0.097\n",
      "cleanliness_mentioned: delta = 0.018\n",
      "price_mentioned: delta = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Use Bayes-Net model to determine variable with highest delta (makes the difference for review)\n",
    "aspects = [\"food_mentioned\", \"service_mentioned\", \"cleanliness_mentioned\", \"price_mentioned\"]\n",
    "low_ratings = {1.0, 2.0, 3.0} # all 5-star scores that represent a \"negative review\"\n",
    "high_ratings = {4.0, 5.0} # good reviews\n",
    "\n",
    "model = DiscreteBayesianNetwork([\n",
    "    (\"food_mentioned\", \"star_rating\"),\n",
    "    (\"service_mentioned\", \"star_rating\"),\n",
    "    (\"cleanliness_mentioned\", \"star_rating\"),\n",
    "    (\"price_mentioned\", \"star_rating\")\n",
    "])\n",
    "\n",
    "model.fit(df, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "\n",
    "# Run inference queries\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "def get_yes_prob(var, rating:float):\n",
    "    query = inference.query(variables=[var], evidence={\"star_rating\": rating})\n",
    "    try:\n",
    "        yes_index = query.state_names[var].index(\"yes\")\n",
    "        return query.values[yes_index]\n",
    "    except ValueError:\n",
    "        # this means \"yes\" isn't in this dist.\n",
    "        return 0.0\n",
    "    \n",
    "\n",
    "# Average over group of ratings\n",
    "def get_group_prob(var, rating_group):\n",
    "    probs = [get_yes_prob(var, r) for r in rating_group]\n",
    "    return sum(probs) / len(probs)\n",
    "\n",
    "# P(mention=yes | low) - P(mention=yes | high)\n",
    "delta_results = []\n",
    "\n",
    "for var in aspects:\n",
    "    low_avg = get_group_prob(var, low_ratings)\n",
    "    high_avg = get_group_prob(var, high_ratings)\n",
    "    delta = low_avg - high_avg\n",
    "    delta_results.append((var, delta))\n",
    "    print(f\"{var}: delta = {delta:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c49f7",
   "metadata": {},
   "source": [
    "We'll be using our trained Bayes Net to predict the most likely star_rating for each review based on our four defined features. This will help us evaluate if the model is able to recover any relevant/accurate user sentiment from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35f740cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Prediction Accuracy\n",
    "\n",
    "def predict_star(row):\n",
    "    evidence = {col: row[col] for col in [\"food_mentioned\", \"service_mentioned\", \"cleanliness_mentioned\", \"price_mentioned\"]}\n",
    "    result = inference.map_query(variables=[\"star_rating\"], evidence=evidence, show_progress=False)\n",
    "    return result[\"star_rating\"]\n",
    "\n",
    "df[\"predicted_rating\"] = df.apply(predict_star, axis=1)\n",
    "accuracy = accuracy_score(df[\"star_rating\"], df[\"predicted_rating\"])\n",
    "print(f\"Prediction Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e0a79",
   "metadata": {},
   "source": [
    "Using MAP inference we were able to predict star ratings with a 51% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "047f6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'food_mentioned': 0.0001564926062945695, 'service_mentioned': 0.038482729327863174, 'cleanliness_mentioned': 0.0033236887831593932, 'price_mentioned': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# KL Divergence\n",
    " \n",
    "kl_divergences = {}\n",
    "\n",
    "def get_distribution(var, rating_group):\n",
    "    dists = []\n",
    "    for r in rating_group:\n",
    "        result = inference.query(variables=[var], evidence={\"star_rating\": float(r)})\n",
    "        dists.append(result.values)\n",
    "    return np.mean(dists, axis=0)\n",
    "\n",
    "for var in [\"food_mentioned\", \"service_mentioned\", \"cleanliness_mentioned\", \"price_mentioned\"]:\n",
    "    p_low = get_distribution(var, low_ratings)\n",
    "    p_high = get_distribution(var, high_ratings)\n",
    "    kl = entropy(p_low, p_high)\n",
    "    kl_divergences[var] = kl\n",
    "\n",
    "print(kl_divergences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
